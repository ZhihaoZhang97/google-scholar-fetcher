name: Update Google Scholar Records (with Proxy)

on:
  schedule:
    - cron: "0 0 1 * *"  # Runs at midnight on the 1st of every month
  workflow_dispatch:     # Allows manual triggering

permissions:
  contents: write
  
jobs:
  update-scholar:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      # Install proxy packages
      - name: Install proxy dependencies
        run: npm install -g proxy-agent
      
      # Ensure target directory exists
      - name: Create directory for record file if needed
        run: |
          mkdir -p $(dirname "${{ vars.RECORD_FILE }}")
      
      # Update index.js to use proxy
      - name: Modify script to use proxy
        run: |
          cat <<'EOF' > proxy-fetch.js
          const core = require('@actions/core');
          const fsp = require('fs/promises');
          const parse = require('node-html-parser').parse;
          const { HttpsProxyAgent } = require('proxy-agent');
          
          // Public proxy service - consider using a more robust solution for production
          const proxyUrl = 'https://api.allorigins.win/raw?url=';
          
          // Common headers to make requests appear more like a browser
          const fetchHeaders = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
              'Accept-Language': 'en-US,en;q=0.9',
              'Cache-Control': 'no-cache',
              'Pragma': 'no-cache'
          };
          
          async function fetchWithProxy(url, options = {}) {
              try {
                  // Use proxy agent
                  const proxyOptions = { ...options };
                  if (!proxyOptions.agent) {
                      proxyOptions.agent = new HttpsProxyAgent();
                  }
                  
                  const response = await fetch(url, proxyOptions);
                  return response;
              } catch (error) {
                  console.log("Direct fetch failed, trying through public proxy");
                  // Fallback to public proxy service
                  const encodedUrl = encodeURIComponent(url);
                  const proxyResponse = await fetch(`${proxyUrl}${encodedUrl}`);
                  return proxyResponse;
              }
          }
          
          async function fetchRange(start, end) {
              const publications = [];
              
              try {
                  // Adding delay to avoid rate limiting
                  await new Promise(resolve => setTimeout(resolve, 3000));
                  
                  const url = `https://scholar.google.com/citations?user=${core.getInput('google-scholar-id')}&cstart=${start}&pagesize=${end}`;
                  const record = await fetchWithProxy(url, {
                      method: 'POST',
                      body: 'json=1',
                      headers: fetchHeaders
                  });
                  
                  if (!record.ok) {
                      throw new Error(`Failed to fetch publications: ${record.status} ${record.statusText}`);
                  }
                  
                  const recordText = await record.text();
                  let recordJson;
                  
                  try {
                      recordJson = JSON.parse(recordText);
                  } catch (e) {
                      console.error("Failed to parse JSON response. Response starts with:", recordText.substring(0, 100));
                      throw new Error("Invalid JSON response from Google Scholar");
                  }
                  
                  const recordHTML = recordJson.B;
                  const dom = parse(recordHTML);
                  
                  for (const row of dom.childNodes) {
                      // Adding delay between requests to avoid rate limiting
                      await new Promise(resolve => setTimeout(resolve, 5000));
                      
                      try {
                          const citationId = row.childNodes[0].childNodes[0].getAttribute('href').split(':')[1];
                          const detailUrl = `https://scholar.google.com/citations?view_op=view_citation&hl=en&user=${core.getInput('google-scholar-id')}&citation_for_view=${core.getInput('google-scholar-id')}:${citationId}`;
                          
                          const detailedRecord = await fetchWithProxy(detailUrl, {
                              headers: fetchHeaders
                          });
                          
                          if (!detailedRecord.ok) {
                              console.warn(`Warning: Failed to fetch detailed record: ${detailedRecord.status} ${detailedRecord.statusText}`);
                              continue;
                          }
                          
                          const detailedRecordHTML = await detailedRecord.text();
                          const detailedRecordDom = parse(detailedRecordHTML);
                          const detailedRecordInfo = detailedRecordDom.getElementById('gsc_oci_table');
                          
                          if (!detailedRecordDom.getElementById('gsc_oci_title')) {
                              console.warn('Warning: Unable to parse publication title');
                              continue;
                          }
                          
                          const detailedRecordJson = {
                              'title': detailedRecordDom.getElementById('gsc_oci_title').childNodes[0].innerHTML,
                              'link': detailedRecordDom.getElementById('gsc_oci_title').childNodes[0].getAttribute('href')
                          };
                          
                          for (const detailedRecordInfoItem of detailedRecordInfo.childNodes) {
                              switch (detailedRecordInfoItem.childNodes[0].innerHTML) {
                                  case 'Authors':
                                      detailedRecordJson['authors'] = detailedRecordInfoItem.childNodes[1].innerHTML.split(', ');
                                      break;
                                  case 'Publication date':
                                      detailedRecordJson['date'] = detailedRecordInfoItem.childNodes[1].innerHTML.split('/').map(element => parseInt(element));
                                      break;
                                  case 'Journal':
                                      detailedRecordJson['journal'] = detailedRecordInfoItem.childNodes[1].innerHTML;
                                      break;
                                  case 'Conference':
                                      detailedRecordJson['journal'] = detailedRecordInfoItem.childNodes[1].innerHTML;
                                      break;
                                  case 'Volume':
                                      detailedRecordJson['volume'] = detailedRecordInfoItem.childNodes[1].innerHTML;
                                      break;
                                  case 'Pages':
                                      detailedRecordJson['pages'] = detailedRecordInfoItem.childNodes[1].innerHTML;
                                      break;
                                  case 'Publisher':
                                      detailedRecordJson['publisher'] = detailedRecordInfoItem.childNodes[1].innerHTML;
                                      break;
                                  case 'Description':
                                      detailedRecordJson['description'] = detailedRecordInfoItem.childNodes[1].innerHTML.replaceAll(/(<([^>]+)>)/ig, '');;
                                      break;
                                  case 'Total citations':
                                      detailedRecordJson['citations'] = parseInt(detailedRecordInfoItem.childNodes[1].childNodes[0].childNodes[0].innerHTML.match(/\d+/g)[0]);
                                      break;
                              }
                          }
                          publications.push(detailedRecordJson);
                      } catch (error) {
                          console.error(`Error processing publication: ${error.message}`);
                      }
                  }
              } catch (error) {
                  console.error(`Error in fetchRange: ${error.message}`);
                  throw error;
              }
              
              return publications;
          }
          
          async function fetchRecord(start = 0, step = 100) {
              try {
                  var totalPublications = [];
                  var start = 0, end = step;
                  while (true) {
                      var pagePublications = await fetchRange(start, end);
                      totalPublications = totalPublications.concat(pagePublications);
                      if (pagePublications.length < step) {
                          break;
                      } else {
                          start += step;
                          end += step;
                      }
                  }
                  
                  const recordFile = core.getInput('record-file');
                  if (recordFile != '') {
                      await fsp.writeFile(recordFile, JSON.stringify(totalPublications));
                      console.log(`Successfully wrote ${totalPublications.length} publications to ${recordFile}`);
                  } else {
                      core.setOutput('record', JSON.stringify(totalPublications));
                      console.log(`Successfully fetched ${totalPublications.length} publications`);
                  }
              } catch (error) {
                  console.error(`Failed: ${error.message}`);
                  core.setFailed(error.message);
              }
          }
          
          fetchRecord().finally();
          EOF
      
      # Run with the proxy script
      - name: Fetch Google Scholar Records with Proxy
        id: scholar-fetch
        run: |
          node proxy-fetch.js
        env:
          INPUT_GOOGLE-SCHOLAR-ID: ${{ vars.GOOGLE_SCHOLAR_ID }}
          INPUT_RECORD-FILE: ${{ vars.RECORD_FILE }}
      
      # Create an empty file if it doesn't exist (first run)
      - name: Create empty file if it doesn't exist
        run: |
          if [ ! -f "${{ vars.RECORD_FILE }}" ]; then
            echo "[]" > ${{ vars.RECORD_FILE }}
          fi
      
      - name: Track record file changes
        run: git add ${{ vars.RECORD_FILE }}

      - name: Check if file changed
        id: changed
        continue-on-error: true
        run: git diff --exit-code ${{ vars.RECORD_FILE }}

      - name: Check if staged file changed
        id: cached
        continue-on-error: true
        run: git diff --exit-code --cached ${{ vars.RECORD_FILE }}

      - name: Commit and push if changed
        if: ${{ steps.changed.outcome == 'failure' || steps.cached.outcome == 'failure' }}
        run: |
          git config --global user.name '${{ vars.GIT_USERNAME || 'GitHub Action' }}'
          git config --global user.email '${{ vars.GIT_EMAIL || 'action@github.com' }}'
          git commit -am "Update Google Scholar records"
          git push 